{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном ноутбуке рассмотрим экстрактивный подход к суммаризации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "news = pd.read_csv('../data/news10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new1 = news.iloc[0]\n",
    "text = new1['text']\n",
    "sentences = text.split('.')\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_for_word2vec = news['text'].apply(lambda x: x.split('.')) # split text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['бой у сопоцкина и друскеник закончиться отступление германец', 'неприятель, приблизиться с север к осовца начать артиллерийский борьба с крепость', 'в артиллерийский бой принимать участие тяжёлый калибр', 'с ранний утро 14 сентябрь огонь достигнуть значительный напряжение', 'попытка германский пехота пробиться близкий к крепость отразить', 'в галиция мы занять дембица', 'больший колонна, отступать по шоссе от перемышль к саноку, обстреливаться с высота наш батарея и бежала, бросить парки, обоз и автомобиль', 'вылазка гарнизон перемышль оставаться безуспешный', 'при продолжаться отступление австриец обнаруживаться полный перемешивание они частей, захватываться новый партия пленных, орудие и прочий материальный часть', 'на перевал ужок мы разбить неприятельский отряд, взять он артиллерия и много пленный и, продолжать преследовать, вступить в предел венгрия', '«русский инвалид», 16 сентябрь 1914 год', '']\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "lemmatized_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    words = sentence.split()\n",
    "    lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
    "    lemmatized_sentence = ' '.join(lemmatized_words)\n",
    "    lemmatized_sentences.append(lemmatized_sentence)\n",
    "\n",
    "print(lemmatized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_sentences_word2vec = []\n",
    "\n",
    "for i in sentences_for_word2vec:\n",
    "    for sentence in i:\n",
    "        words = sentence.split()\n",
    "        lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
    "        lemmatized_sentence = ' '.join(lemmatized_words)\n",
    "        lemmatized_sentences_word2vec.append(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_sentences_word2vec = [sentence.split() for sentence in lemmatized_sentences_word2vec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экстрактивная суммаризация на основе вхождения общих слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(sentences):\n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(i+1, len(sentences)):\n",
    "            sentence1 = sentences[i]\n",
    "            sentence2 = sentences[j]\n",
    "            \n",
    "            words1 = sentence1.split()\n",
    "            words2 = sentence2.split()\n",
    "            \n",
    "            common_words = set(words1) & set(words2)\n",
    "            similarity = len(common_words) / (len(words1) + len(words2))\n",
    "            if similarity > 0:\n",
    "                similarities.append((sentence1, sentence2, similarity, i , j))\n",
    "    \n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('неприятель, приблизиться с север к осовца начать артиллерийский борьба с '\n",
      "  'крепость',\n",
      "  'попытка германский пехота пробиться близкий к крепость отразить',\n",
      "  0.10526315789473684,\n",
      "  1,\n",
      "  4),\n",
      " ('в артиллерийский бой принимать участие тяжёлый калибр',\n",
      "  'в галиция мы занять дембица',\n",
      "  0.08333333333333333,\n",
      "  2,\n",
      "  5)]\n",
      " Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью\n",
      " Попытка германской пехоты пробиться ближе к крепости отражена\n",
      " В артиллерийском бою принимают участие тяжелые калибры\n",
      " В Галиции мы заняли Дембицу\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "similarities = calculate_similarity(lemmatized_sentences)\n",
    "similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "pprint(similarities[:2])\n",
    "for i in range(2):\n",
    "    print(sentences[similarities[i][3]])\n",
    "    print(sentences[similarities[i][4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экстрактивная суммаризация на основе обученных векторных представлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13229930, 15177920)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(lemmatized_sentences_word2vec, min_count=1)\n",
    "\n",
    "model.train(lemmatized_sentences_word2vec, total_examples=model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding = []\n",
    "\n",
    "for sentence in lemmatized_sentences:\n",
    "    words = sentence.split()\n",
    "    embedding = sum([model.wv[word] for word in words])\n",
    "    sentence_embedding.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.31649372, 0, 1),\n",
       " (0.4989151, 0, 2),\n",
       " (0.37511656, 0, 3),\n",
       " (0.37333974, 0, 4),\n",
       " (0.3338399, 0, 5),\n",
       " (0.46066606, 0, 6),\n",
       " (0.37298033, 0, 7),\n",
       " (0.42174768, 0, 8),\n",
       " (0.55801576, 0, 9),\n",
       " (0.14970517, 0, 10),\n",
       " (0.37316564, 1, 2),\n",
       " (0.59505117, 1, 3),\n",
       " (0.6071144, 1, 4),\n",
       " (0.33905736, 1, 5),\n",
       " (0.72942156, 1, 6),\n",
       " (0.2393505, 1, 7),\n",
       " (0.44585058, 1, 8),\n",
       " (0.48829982, 1, 9),\n",
       " (0.20476171, 1, 10),\n",
       " (0.40791482, 2, 3),\n",
       " (0.2869617, 2, 4),\n",
       " (0.26325667, 2, 5),\n",
       " (0.48787487, 2, 6),\n",
       " (0.40069795, 2, 7),\n",
       " (0.4622263, 2, 8),\n",
       " (0.45909458, 2, 9),\n",
       " (0.21284302, 2, 10),\n",
       " (0.37572986, 3, 4),\n",
       " (0.28212357, 3, 5),\n",
       " (0.6137512, 3, 6),\n",
       " (0.20154104, 3, 7),\n",
       " (0.39688435, 3, 8),\n",
       " (0.4170017, 3, 9),\n",
       " (0.60179204, 3, 10),\n",
       " (0.43817982, 4, 5),\n",
       " (0.55983496, 4, 6),\n",
       " (0.26581037, 4, 7),\n",
       " (0.38130057, 4, 8),\n",
       " (0.47588485, 4, 9),\n",
       " (0.18579806, 4, 10),\n",
       " (0.40776572, 5, 6),\n",
       " (0.38305175, 5, 7),\n",
       " (0.41879508, 5, 8),\n",
       " (0.7073965, 5, 9),\n",
       " (0.095969535, 5, 10),\n",
       " (0.38034979, 6, 7),\n",
       " (0.6048609, 6, 8),\n",
       " (0.61098987, 6, 9),\n",
       " (0.21413279, 6, 10),\n",
       " (0.29427147, 7, 8),\n",
       " (0.51393384, 7, 9),\n",
       " (-0.03736831, 7, 10),\n",
       " (0.669873, 8, 9),\n",
       " (0.1432222, 8, 10),\n",
       " (0.10793455, 9, 10)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = []\n",
    "\n",
    "for i in range(len(sentence_embedding)):\n",
    "    for j in range(i+1, len(sentence_embedding)):\n",
    "        embedding1 = sentence_embedding[i]\n",
    "        embedding2 = sentence_embedding[j]\n",
    "        if isinstance(embedding1, int) or isinstance(embedding2, int):\n",
    "            continue\n",
    "\n",
    "        if embedding1.all() == 0 or embedding2.all() == 0:\n",
    "            continue\n",
    "\n",
    "        similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "        similarity_matrix.append((similarity, i, j))\n",
    "\n",
    "similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_variables = sorted(similarity_matrix, key=lambda x: x[0], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью\n",
      " Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили\n",
      " В Галиции мы заняли Дембицу\n",
      " На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии\n"
     ]
    }
   ],
   "source": [
    "result = ranked_variables[:2]\n",
    "\n",
    "for i in range(2):\n",
    "    print(sentences[result[i][1]])\n",
    "    print(sentences[result[i][2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
